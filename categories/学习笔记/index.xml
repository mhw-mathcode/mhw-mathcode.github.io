<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>学习笔记 on mhw</title>
        <link>https://mhw-mathcode.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</link>
        <description>Recent content in 学习笔记 on mhw</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>mhw-mathcode</copyright>
        <lastBuildDate>Fri, 04 Jul 2025 13:08:34 +0000</lastBuildDate><atom:link href="https://mhw-mathcode.github.io/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>学习笔记-数据结构</title>
        <link>https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</link>
        <pubDate>Sun, 22 Jun 2025 11:50:20 +0800</pubDate>
        
        <guid>https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</guid>
        <description>&lt;h2 id=&#34;1-线性表&#34;&gt;1. 线性表
&lt;/h2&gt;&lt;p&gt;数据结构三要素：逻辑结构、数据的运算、存储结构。&lt;/p&gt;
&lt;p&gt;线性表是具有相同数据类型的n(n&amp;gt;=0)个数据元素的有限序列。（逻辑结构）&lt;/p&gt;
&lt;p&gt;基本操作：创建、销毁、插入、删除、按值查找、按位查找。&lt;/p&gt;
&lt;p&gt;顺序表 = 线性表 + 顺序存储（静态分配 or 动态分配）&lt;/p&gt;
&lt;p&gt;链表 = 线性表 + 链式存储（单链表、双链表、循环单链表、循环双链表、静态链表）&lt;/p&gt;
&lt;h2 id=&#34;2-栈和队列&#34;&gt;2. 栈和队列
&lt;/h2&gt;&lt;p&gt;栈是只允许在一段进行查如或者删除操作的线性表。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;n 个不同元素进栈，出栈元素不同排列的个数为 $\frac{1}{n+1} C_{2n}^n$ （卡特兰数）。&lt;/li&gt;
&lt;li&gt;顺序栈（共享栈）、链栈&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;队列是只能在队尾插入、在队首删除的线性表。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顺序队列、循环队列、链式队列、双端队列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;表达式求值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中缀转后缀：
&lt;ul&gt;
&lt;li&gt;（手算）先确定各个运算符的顺序，然后按照 [左操作数 右操作数 运算符] 的方式组合。&lt;/li&gt;
&lt;li&gt;（机算）
&lt;ul&gt;
&lt;li&gt;遇到操作数直接加入后缀表达式；&lt;/li&gt;
&lt;li&gt;遇到界限符，遇到 ( 直接入栈，遇到 ) 则依次弹出栈内运算符并加入后缀表达式，直到弹出 ( 为止；&lt;/li&gt;
&lt;li&gt;遇到运算符，依次弹出栈中优先级高于或等于当前运算符的所有运算符，并加入后缀表达式，若碰到 ( 或栈空则停止。之后再把当前运算符入栈。处理完所有字符后，将栈中剩余运算符依次弹出，并加入后缀表达式。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;后缀表达式（逆波兰表达式）计算：
&lt;ul&gt;
&lt;li&gt;从左往右扫描后缀表达式；&lt;/li&gt;
&lt;li&gt;扫描操作数入栈；&lt;/li&gt;
&lt;li&gt;扫描操作符，弹出两个栈顶元素，计算结果入栈。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;中缀表达式计算：
&lt;ul&gt;
&lt;li&gt;初始化两个栈，操作数栈和运算符栈；&lt;/li&gt;
&lt;li&gt;若扫描到操作数，压入操作数栈；&lt;/li&gt;
&lt;li&gt;若扫描到运算符或界限符，则按照“中级转后缀”相同的逻辑压入运算符栈（期间会弹出运算符，每当弹出一个运算符时，需弹出两个操作数栈的栈顶元素并执行运算，结果压回操作数栈）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/4.png&#34;
	width=&#34;406&#34;
	height=&#34;224&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/4_hu_241a7f506e078edc.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/4_hu_3d75ca22ba6202cd.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;举个例子&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;435px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;特殊矩阵压缩存储：对阵矩阵，三角矩阵，三对角矩阵，稀疏矩阵（三元组、十字链表法）。&lt;/p&gt;
&lt;h2 id=&#34;3-串&#34;&gt;3. 串
&lt;/h2&gt;&lt;p&gt;串是由零个或多个字符组成的有限序列。&lt;/p&gt;
&lt;p&gt;KMP 算法（时间复杂度 $O(n+m)$）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当主串与模式串 $S$ 不匹配时，主串 $i$ 不回溯，模式串 $j=next[j]$ （模式串的 $next$ 数组）。&lt;/li&gt;
&lt;li&gt;$next[j]$：由1~j-1个字符组成的串最长相等前后缀长度+1（取决于下标从 0 还是 1 开始）。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// T[i]表示后缀的单个字符, T[j]表示前缀的单个字符
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;c1&#34;&gt;// 如果字符不相同，则j值回溯
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;next&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;$nextval[j]$：$next$ 数组的优化
&lt;ul&gt;
&lt;li&gt;如果 $S[next[j]]==S[j]$ ，表明这其实是一次无效的比较，$nextval[j]=nextval[next[j]]$；&lt;/li&gt;
&lt;li&gt;否则，$nextval[j]=next[j]$。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-树&#34;&gt;4. 树
&lt;/h2&gt;&lt;h3 id=&#34;概念与性质&#34;&gt;概念与性质
&lt;/h3&gt;&lt;p&gt;结点的度：结点的分支数
树的度：树中各结点的度的最大值
结点数=总度数（边数）+1&lt;/p&gt;
&lt;p&gt;m叉树：可以所有结点的度都 $&amp;lt;= m$（结点的度最大为 $m$ ，可以为空树）
度为m的树：至少一个结点的度 $= m$（至少 $m+1$ 个结点）&lt;/p&gt;
&lt;h3 id=&#34;二叉树&#34;&gt;二叉树
&lt;/h3&gt;&lt;p&gt;二叉树是度为 2 的有序树（每个结点至多两个子树，左右子树不能颠倒）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;满二叉树：不存在度为 1 的结点。&lt;/li&gt;
&lt;li&gt;完全二叉树：在满二叉树的基础上，从最后一个结点开始去结点。&lt;/li&gt;
&lt;li&gt;二叉排序树：左子树关键字均小于根节点的关键字，右子树关键字均大于根节点的关键字。&lt;/li&gt;
&lt;li&gt;平衡二叉树（平衡二叉搜索树）：树上任意一个结点的左子树和右子树深度之差不超过 1 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;顺序存储（左儿子 $i&lt;em&gt;2$ ，右儿子 $i&lt;/em&gt;2+1$ ）、链式存储&lt;/p&gt;
&lt;p&gt;性质：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;二叉树：叶子结点（度为 0 的结点）的数量比度为 2 的结点的数量多一个&lt;/li&gt;
&lt;li&gt;具有 n 个结点的完全二叉树的高度为 $h = \lceil \log_2 (n + 1) \rceil$ 或 $h = \lfloor \log_2 n \rfloor + 1$ 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;遍历二叉树：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先序遍历：根 &amp;ndash;&amp;gt; 左 &amp;ndash;&amp;gt; 右&lt;/li&gt;
&lt;li&gt;中序遍历：左 &amp;ndash;&amp;gt; 根 &amp;ndash;&amp;gt; 右&lt;/li&gt;
&lt;li&gt;后序遍历：左 &amp;ndash;&amp;gt; 右 &amp;ndash;&amp;gt; 根&lt;/li&gt;
&lt;li&gt;层序遍历：$bfs$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由遍历序列构造二叉树：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前序+中序&lt;/li&gt;
&lt;li&gt;后序+中序&lt;/li&gt;
&lt;li&gt;层序+中序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;线索二叉树：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;定义&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// 左、右线索标志
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;typedef&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ThreadNode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;ElemType&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ThreadNode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;lchild&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rchild&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lTag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;rTag&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// 0指向孩子；1指向线索
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1.png&#34;
	width=&#34;1010&#34;
	height=&#34;648&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1_hu_23bd51cca5ab60f9.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/1_hu_c265e840dc61adb8.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;线索二叉树&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;155&#34;
		data-flex-basis=&#34;374px&#34;
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中序线索化（先序、后序类似）
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/2.jpg&#34;
	width=&#34;1104&#34;
	height=&#34;702&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/2_hu_baf945ac8f6465cf.jpg 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/2_hu_35955af97ad8c624.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;中序线索化&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;157&#34;
		data-flex-basis=&#34;377px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;应用：找中序后继（剩余同理）
&lt;ul&gt;
&lt;li&gt;在中序线索二叉树中，如果 $p \rightarrow rTag==1$ ，右孩子指针被线索化了，那么直接得到中序后继；&lt;/li&gt;
&lt;li&gt;若 $p \rightarrow rTag==0$ ，有右孩子。就要找右子树得中序遍历最左边的结点。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;树与森林&#34;&gt;树与森林
&lt;/h3&gt;&lt;p&gt;树的存储结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;双亲表示法（顺序存储）&lt;/li&gt;
&lt;li&gt;孩子表示法（顺序存储+链式存储）&lt;/li&gt;
&lt;li&gt;孩子兄弟表示法（顺序存储+链式存储，左指针指向儿子，右指针指向兄弟）（树、森林与二叉树的转换）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;树的遍历：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先根遍历：先访问根节点，再对每颗子树进行先根遍历；树的先根遍历序列和 对应的二叉树的先序序列相同。&lt;/li&gt;
&lt;li&gt;后根遍历：先对每颗子树进行后根遍历，再访问根节点；树的后根遍历序列和对应的二叉树的中序序列相同。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;森林的遍历：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先序遍历&lt;/li&gt;
&lt;li&gt;中序遍历&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用&#34;&gt;应用
&lt;/h3&gt;&lt;p&gt;二叉排序树（BST）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;二叉排序树，又叫二叉查找树（Binary Search Tree），其左子树关键字均小于根节点的关键字，右子树关键字均大于根节点的关键字。&lt;/li&gt;
&lt;li&gt;查找、插入、构造、删除（度为 2 的结点需要找前驱或者后继）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;平衡二叉树（AVL）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平衡因子 = 左子树高 - 右子树高，任一结点平衡因子绝对值小于 1。&lt;/li&gt;
&lt;li&gt;插入：
&lt;ul&gt;
&lt;li&gt;每次只需调整最小不平衡子树。
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/3.png&#34;
	width=&#34;914&#34;
	height=&#34;526&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/3_hu_d634cbd74a449c74.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/3_hu_e5e0aaceecfabadb.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;调整最小不平衡子树&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;173&#34;
		data-flex-basis=&#34;417px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;高度为 h 时最少有 $\frac{h*(h-1)}{2}+1$ 个结点。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;哈夫曼树：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;哈夫曼树：带权路径长度（WPL）最小的二叉树
&lt;ul&gt;
&lt;li&gt;结点的带权路径长度：从根结点到该结点的路径长度 * 权值&lt;/li&gt;
&lt;li&gt;树的带权路径长度：所有叶结点的带权路径长度之和&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;构造：
&lt;ul&gt;
&lt;li&gt;选权值最小的两个结点；&lt;/li&gt;
&lt;li&gt;在剩下的结点中挑一个最小的结点继续结合；或者挑两个结点先结合。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;性质：
&lt;ul&gt;
&lt;li&gt;结点总数为 $2*n-1$&lt;/li&gt;
&lt;li&gt;不存在度为 1 的结点&lt;/li&gt;
&lt;li&gt;哈夫曼树不唯一&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;哈夫曼编码：
&lt;ul&gt;
&lt;li&gt;固定长度编码：每个字符用相等长度的二进制位表示&lt;/li&gt;
&lt;li&gt;可变长度编码：允许对不同字符用不等长的二进制位表示&lt;/li&gt;
&lt;li&gt;前缀编码：没有一个编码是另一个编码的前缀&lt;/li&gt;
&lt;li&gt;将字符频次作为字符结点权值，构造哈夫曼树，可得到哈夫曼编码，可用于数据压缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-图&#34;&gt;5. 图
&lt;/h2&gt;&lt;h3 id=&#34;概念&#34;&gt;概念
&lt;/h3&gt;&lt;p&gt;图 G 就是由点集 V 和边集 E 组成的。
无向图和有向图：有向边 &amp;lt;A, B&amp;gt; （弧尾，弧头），无向边 (A, B)
简单图：不存在重复的边；多重图：存在重复的边。
顶点的度 = 入度 + 出度
简单路径：顶点不重复出现；简单回路：除了头顶点和尾顶点，其余顶点里不出现重复的顶点。&lt;/p&gt;
&lt;p&gt;连通性：无向图中，$v — … — w$ （v，w之间是连通的）；
强连通性：有向图中，既有$v \rightarrow … \rightarrow w$ ，又有 $v \leftarrow … \leftarrow w$ ，（v，w 之间是强连通的）。
连通图：在无向图中，任意两个点连通；
强连通图：在有向图中，任意两个点强连通。最少有 n 条边（形成回路）。&lt;/p&gt;
&lt;p&gt;子图：部分点集+部分边集，每条边的两个点一定存在。
生成子图：子图包含原图的所有顶点，可以去掉一些边。
连通分量：在无向图中极大的连通子图
强连通分量：在有向图中极大的强连通子图&lt;/p&gt;
&lt;p&gt;生成树：对于连通图，包含图中所有顶点的极小连通子图
生成森林：对于非连通图，各连通分量的生成树组成了生成森林&lt;/p&gt;
&lt;p&gt;存储：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;邻接矩阵&lt;/li&gt;
&lt;li&gt;邻接表&lt;/li&gt;
&lt;li&gt;十字链表
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/5.png&#34;
	width=&#34;604&#34;
	height=&#34;330&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/5_hu_7389397805e72b7b.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/5_hu_1ca7bc0d5e958c03.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;十字链表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;183&#34;
		data-flex-basis=&#34;439px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;邻接多重表
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/6.png&#34;
	width=&#34;659&#34;
	height=&#34;384&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/6_hu_9f6f6e7fca2cd558.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/6_hu_b3b46207076e4988.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;邻接多重表&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;171&#34;
		data-flex-basis=&#34;411px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;应用-1&#34;&gt;应用
&lt;/h3&gt;&lt;p&gt;最小生成树（MST）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Prim$ ：$O(n^2)$，每次遍历所有结点找到加入 MST 的代价 $lowcast$ 最低的结点，然后用改结点更新所有结点的 $lowcast$。&lt;/li&gt;
&lt;li&gt;$Kruskal$ ：$O(|E|log|E|)$，每次选择一条权值最小的且该边两端结点不连通的边。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最短路：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单源最短路：
&lt;ul&gt;
&lt;li&gt;$BFS$ ：无权图&lt;/li&gt;
&lt;li&gt;$Dijkstra$ ：正权图，优先队列优化 $O(nlogn)$ 。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;多源最短路：
&lt;ul&gt;
&lt;li&gt;$Floyd$ ：无负权回路的图&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有向无环图（Directed Acyclic Graph）描述表达式：
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/7.png&#34;
	width=&#34;760&#34;
	height=&#34;417&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/7_hu_71236bd49094b669.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/7_hu_18a87af0079ec168.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;DAG 描述表达式&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;437px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;拓扑排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AOV：顶点表示活动的网（Activity On Vertex Network）&lt;/li&gt;
&lt;li&gt;DAG 表示一个工程（工程就是活动的顺序序列集合）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关键路径：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AOE：顶点表示事件，有向边表示活动，边的权值表示该活动的花销，称为 AOE 网（Activity On Edge Network）。&lt;/li&gt;
&lt;li&gt;从源点到汇点的有向路径中，长度最大的路径成为关键路径，关键路径上的活动成为关键活动。
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/8.png&#34;
	width=&#34;902&#34;
	height=&#34;476&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/8_hu_4a9e22be7c1f83f5.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/8_hu_b561ba9255578f2d.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;关键路径求解方法&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;189&#34;
		data-flex-basis=&#34;454px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;特性：
&lt;ul&gt;
&lt;li&gt;若关键活动耗时增加，则整个工程的工期将增长&lt;/li&gt;
&lt;li&gt;缩短关键活动的时间，可以缩短整个工程的工期&lt;/li&gt;
&lt;li&gt;当缩短到一定程度时，关键活动可能会变成非关键活动&lt;/li&gt;
&lt;li&gt;可能有多条关键路径，只提高一条关键路径上的关键活动速度并不能缩短整个工程的工期，只有加快那些包括在所有关键路径上的关键活动才能达到缩短工期的目的。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;6-查找b树散列表&#34;&gt;6. 查找（B树、散列表）
&lt;/h2&gt;&lt;h3 id=&#34;概念-1&#34;&gt;概念
&lt;/h3&gt;&lt;p&gt;查找表：用于查找的数据集合。
静态查找表（仅查找）、动态查找表（插删操作）。
平均查找长度（ASL）：所有查找过程中关键字的比较次数的平均值。&lt;/p&gt;
&lt;p&gt;顺序查找、折半查找、分块查找（又叫索引顺序查找，块内无序、块间有序）&lt;/p&gt;
&lt;p&gt;B 树：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;B 树，又称多路平衡查找树，B 树中所有结点的孩子个数的最大值称为 B 树的阶，通常用 m 表示。一棵 m 阶 B 树或为空树，或为满足如下特性的 m 叉树：
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/9.png&#34;
	width=&#34;641&#34;
	height=&#34;286&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/9_hu_c2be0817c8ae6b50.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/9_hu_fd0f862df7cb5de.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;B 树&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;224&#34;
		data-flex-basis=&#34;537px&#34;
	
&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;树中每个结点至多有 m 棵子树，即至多含有 m-1 个关键字。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若根结点不是终端结点，则至少有两棵子树。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;除根结点外的所有非叶结点至少有 $⌊m/2⌋$ 棵子树，即至少含有 $⌊m/2⌋-1$ 个关键字。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有非叶结点的结构如下，其中，$K_i（i = 1, 2, &amp;hellip;, n）$ 为结点的关键字，且满足 $K_1 &amp;lt; K_2 &amp;lt; &amp;hellip; &amp;lt; K_n$ ；$P_i（i = 0, 1, &amp;hellip;, n）$ 为指向子树根结点的指针，且指针 $P_{i-1}$ 所指子树中所有结点的关键字均小于 $K_i$，$P_i$ 所指子树中所有结点的关键字均大于 $K_i$ ，$n（⌊m/2⌋ - 1 ≤ n ≤ m - 1）$ 为结点中关键字的个数。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;n&lt;/th&gt;
          &lt;th&gt;P₀&lt;/th&gt;
          &lt;th&gt;K₁&lt;/th&gt;
          &lt;th&gt;P₁&lt;/th&gt;
          &lt;th&gt;K₂&lt;/th&gt;
          &lt;th&gt;P₂&lt;/th&gt;
          &lt;th&gt;&amp;hellip;&lt;/th&gt;
          &lt;th&gt;Kₙ&lt;/th&gt;
          &lt;th&gt;Pₙ&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有的叶结点都出现在同一层次上，并且不带信息（可以视为外部结点或类似于折半查找判定树的查找失败结点，实际上这些结点不存在，指向这些结点的指针为空）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;含 n 个关键字的 m 叉 B 树，高度满足以下不等式：$\log_m(n + 1) \leq h \leq \log_{\lceil m/2 \rceil} \frac{n + 1}{2} + 1$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;插入：在插入 $key$ 后，若导致原结点关键字数超过上限，则从中间位置（$⌊m/2⌋$）将其中的关键字分为两部分，左部分包含的关键字放在原结点中，右部分包含的关键字放到新结点中，中间位置（$⌊m/2⌋$）的结点插入原结点的父结点。若此时导致其父结点的关键字个数也超过了上限，则继续进行这种分裂操作，直至这个过程传到根结点为止，进而导致 B 树高度增加 1。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;删除：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;删除非终端节点，找直接前驱或直接后继，转化为终端结点的删除；&lt;/li&gt;
&lt;li&gt;删除终端结点
&lt;ul&gt;
&lt;li&gt;删除后结点关键字个数未低于下限，直接删除；&lt;/li&gt;
&lt;li&gt;若低于下限：
&lt;ul&gt;
&lt;li&gt;兄弟够借：左兄弟富裕，用该结点前驱的前驱填补，右同理;&lt;/li&gt;
&lt;li&gt;兄弟不够借：左右兄弟关键字均 $=\lceil m/2 \rceil - 1$，将左（右）兄弟结点及双亲结点中的关键字进行合并。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;B+ 树：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;m 个关键字，对应 m 个分支，m 个子树，查找信息并不会停留在分支节点上，会一直查找到叶子结点。
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/10.png&#34;
	width=&#34;769&#34;
	height=&#34;303&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/10_hu_540d4cee62fc6ce9.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/10_hu_93524166148a8cd6.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;B&amp;#43; 树&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;253&#34;
		data-flex-basis=&#34;609px&#34;
	
&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;散列表：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;也称哈希表，通过散列函数（哈希函数）将关键字与存储地址联系起来。若不同关键字映射到了同一个值，称为冲突（同义词）。冲突越少查找效率越高。&lt;/li&gt;
&lt;li&gt;散列函数：
&lt;ul&gt;
&lt;li&gt;除留余数法：选不大于散列表长度的最大质数，为了让不同的关键字冲突尽可能少。&lt;/li&gt;
&lt;li&gt;直接定址法：$H(key)=a*key+b$ 。&lt;/li&gt;
&lt;li&gt;数字分析法：选取数码分布较为均匀的若干位作为散列地址。&lt;/li&gt;
&lt;li&gt;平方取中法：取关键字平方值的中间几位作为散列地址。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;处理冲突：
&lt;ul&gt;
&lt;li&gt;拉链法：将同义词存储在一个链表中。优化：同一链表中数据有序连接。&lt;/li&gt;
&lt;li&gt;开放地址法：可存放新表项的空闲地址既向他的同义词表项开放，又向他的非同义词表项开放，即 $H_i=(H(key)+d_i) % m $。
&lt;ul&gt;
&lt;li&gt;线性探测法：$d_i=0,1,2,…,m-1$，即发生冲突时每次往后探测相邻的下一个单元是否为空。删除某个结点时需要做一个删除标记，否则会截断在他之后填入的关键字。&lt;/li&gt;
&lt;li&gt;平方探测法：$d_i=0^2,1^2,-1^2,2^2,-2^2,…,k^2,-k^2$，相较于线性探测法更不易于产生聚集问题。&lt;/li&gt;
&lt;li&gt;伪随机序列法：$d_i=某个伪随机序列$。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;再散列法：准备多个散列函数，发生冲突就用下一个。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;7-排序&#34;&gt;7. 排序
&lt;/h2&gt;&lt;p&gt;算法稳定性：关键字相同的两个元素，在排序之后相对位置不变。&lt;/p&gt;
&lt;p&gt;内部排序：数据都在内存中；
外部排序：数据无法全部放在内存中。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;排序算法&lt;/th&gt;
          &lt;th&gt;平均时间复杂度&lt;/th&gt;
          &lt;th&gt;最好情况&lt;/th&gt;
          &lt;th&gt;最坏情况&lt;/th&gt;
          &lt;th&gt;空间复杂度&lt;/th&gt;
          &lt;th&gt;排序方式&lt;/th&gt;
          &lt;th&gt;稳定性&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;冒泡排序&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(n)&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(1)&lt;/td&gt;
          &lt;td&gt;In-place&lt;/td&gt;
          &lt;td&gt;稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;选择排序&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(1)&lt;/td&gt;
          &lt;td&gt;In-place&lt;/td&gt;
          &lt;td&gt;不稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;插入排序&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(n)&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(1)&lt;/td&gt;
          &lt;td&gt;In-place&lt;/td&gt;
          &lt;td&gt;稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;希尔排序&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n log² n)&lt;/td&gt;
          &lt;td&gt;O(n log² n)&lt;/td&gt;
          &lt;td&gt;O(1)&lt;/td&gt;
          &lt;td&gt;In-place&lt;/td&gt;
          &lt;td&gt;不稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;归并排序&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n)&lt;/td&gt;
          &lt;td&gt;Out-place&lt;/td&gt;
          &lt;td&gt;稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;快速排序&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(log n)&lt;/td&gt;
          &lt;td&gt;In-place&lt;/td&gt;
          &lt;td&gt;不稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;堆排序&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(n log n)&lt;/td&gt;
          &lt;td&gt;O(1)&lt;/td&gt;
          &lt;td&gt;In-place&lt;/td&gt;
          &lt;td&gt;不稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;计数排序&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;O(k)&lt;/td&gt;
          &lt;td&gt;Out-place&lt;/td&gt;
          &lt;td&gt;稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;桶排序&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;O(n²)&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;Out-place&lt;/td&gt;
          &lt;td&gt;稳定&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;基数排序&lt;/td&gt;
          &lt;td&gt;O(n × k)&lt;/td&gt;
          &lt;td&gt;O(n × k)&lt;/td&gt;
          &lt;td&gt;O(n × k)&lt;/td&gt;
          &lt;td&gt;O(n + k)&lt;/td&gt;
          &lt;td&gt;Out-place&lt;/td&gt;
          &lt;td&gt;稳定&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;插入排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;直接插入排序：每次将一个待排元素按其关键字大小插入到前面已经排好的子序列中。&lt;/li&gt;
&lt;li&gt;折半插入排序，先用折半查找找到应该插入的位置，再移动元素。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;希尔排序：先将待排序表分割为若干形如 $L[i,i+d,i+2d,…,i+kd]$ 的特殊子表，对各个子表分别进行直接插入排序。缩小增量 $d$ ，重复上述过程直到 $d=1$ 为止。&lt;/p&gt;
&lt;p&gt;交换排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;冒泡排序&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;快速排序：在待排序表 $L[1&amp;hellip;n]$ 中任取一个元素 $pivot$ 作为枢纽（或基准，通常取首元素），通过一趟排序将待排序表划分为独立的两部分 $L[1&amp;hellip;k-1]$ 和 $L[k+1&amp;hellip;n]$，使得 $L[1&amp;hellip;k-1]$ 中的所有元素小于 $pivot$，$L[k+1&amp;hellip;n]$ 中的所有元素大于等于 $pivot$，则 $pivot$ 放在了其最终位置 $L(k)$ 上，这个过程称为一次“划分”。然后分别递归地对两个子表重复上述过程，直至每部分内只有一个元素或空为止，即所有元素放在了其最终位置上。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;选好基准，设置好 $low=1$、$high=n$ 指针；&lt;/li&gt;
&lt;li&gt;因为设置首元素为枢轴元素，所以位置 0 为空，故 $low$ 所指向的位置 0 空，$high$ 先向左遍历；&lt;/li&gt;
&lt;li&gt;若 $high$ 指针指向元素小于基准元素，则把该元素放到 $low$ 指向的空位置，此时 $high$ 指向的位置变为空，则开始向右遍历；&lt;/li&gt;
&lt;li&gt;直到 $low$、$high$ 指针相遇，该轮快排结束。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;将这个过程组织为二叉树，二叉树的层数就是递归调用的层数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;选择排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;简单选择排序：每一次遍历选出最小的元素加入有序子序列。&lt;/li&gt;
&lt;li&gt;堆排序：
&lt;ul&gt;
&lt;li&gt;堆：顺序存储的完全二叉树。结点i的左孩子是 $2i$；右孩子是 $2i+1$；父节点是 $\frac{i}{2}$。编号 $&amp;lt;=\frac{n}{2}$ 的结点都是分支结点&lt;/li&gt;
&lt;li&gt;建堆：编号 $&amp;lt;=\frac{n}{2}$ 的所有结点依次下坠调整，若不满足当前结点小于左右儿子，则将当前结点与更大的一个儿子交换。&lt;/li&gt;
&lt;li&gt;排序：将堆顶元素与堆底元素交换，重新进行下坠操作，使其回复大根堆特性，重复 $n-1$ 趟。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;归并排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;归并：把两个或多个子序列合并为一个。&lt;/li&gt;
&lt;li&gt;归并排序：
&lt;ul&gt;
&lt;li&gt;若 $low &amp;lt; high$，则将序列分从中间 $mid=(low+high)/2$ 分开&lt;/li&gt;
&lt;li&gt;对左半部分 $[low, mid]$ 递归地进行归并排序&lt;/li&gt;
&lt;li&gt;对右半部分 $[mid+1,high]$ 递归地进行归并排序&lt;/li&gt;
&lt;li&gt;将左右两个有序子序列 $Merge$ 为一个&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基数排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将整个关键字拆分为 d 位(或“组”)&lt;/li&gt;
&lt;li&gt;按照各个 关键字位 权重递增的次序(如:个、十、百)，做 d 趟“分配”和“收集”若当前处理的 关键字位 可能取得 r 个值，则需要建立 r 个队列&lt;/li&gt;
&lt;li&gt;分配：顺序扫描各个元素，根据当前处理的关键字位，将元素插入相应队列。一趟分配耗时 $O(n)$&lt;/li&gt;
&lt;li&gt;收集：把各个队列中的结点依次出队并链接。一趟收集耗时 $O(r)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;外部排序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;外部元素太多，无法一次全部读入内存进行排序，采用归并排序的思想和方法。外存中的数据读入内存 → 在内存中排序 → 数据写入外存，总时间开销 = 内部排序所需时间 + 内部归并所需时间 + 外部读写所需时间&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;优化：多路归并&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1.对于 r 个初始归并段进行 k 路归并，需要归并趟数 = $log_k r$（向上取整，归并树高度）&lt;/li&gt;
&lt;li&gt;2.提升外部排序的速度、减少读写磁盘的速度的方法：提高 k 值，降低 r 值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;提高 k 值：增加归并段长度。但是，提高 k 有负面影响：（1）需要的缓存空间升高（ k 路归并需 k 个缓冲区）；（2）内部归并的所需时间提高（选出最小关键字需要进行 k-1 次比较）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;败者树：败者树可视为一棵完全二叉树(多了一个头头)。k 个叶结点分别对应 k 个归并段中当前参加比较的元素，非叶子结点用来记忆左右子树中的“失败者”，而让胜者往上继续进行比较，一直到根结点。使用多路平衡归并可减少归并趟数，构造败者树可以使关键字对比次数减少到 $log_2 k$。
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/11.png&#34;
	width=&#34;852&#34;
	height=&#34;680&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/11_hu_77a5443946bc7360.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/11_hu_78696167a10e1806.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;败者树&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;125&#34;
		data-flex-basis=&#34;300px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;置换-选择排序
设初始待排文件为 FI ，初始归并段输出文件为 FO ，内存工作区为 WA ，FO 和 WA 的初始状态为空，WA 可容纳 w 个记录。置换-选择算法的步骤如下：&lt;/p&gt;
&lt;p&gt;1）从 FI 输入 w 个记录到工作区 WA。
2）从 WA 中选出其中关键字取最小值的记录，记为 MINIMAX 记录。
3）将 MINIMAX 记录输出到 FO 中去。
4）若 FI 不空，则从 FI 输入下一个记录到 WA 中。
5）从 WA 中所有关键字比 MINIMAX 记录的关键字大的记录中选出最小关键字记录，作为新的 MINIMAX 记录。
6）重复3）～5），直至在 WA 中选不出新的 MINIMAX 记录为止，由此得到一个初始归并段，输出一个归并段的结束标志到 FO 中去。
7）重复2）～6），直至 WA 为空。由此得到全部初始归并段。
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/12.jpg&#34;
	width=&#34;571&#34;
	height=&#34;875&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/12_hu_d9339524d9ea49b8.jpg 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/12_hu_61215ba0101bd59a.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;置换-选择排序&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;65&#34;
		data-flex-basis=&#34;156px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;归并树
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/13.png&#34;
	width=&#34;940&#34;
	height=&#34;473&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/13_hu_a911f64e5a868f67.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/13_hu_9af02cccaa4ffe31.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;归并树&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;476px&#34;
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>学习笔记-操作系统</title>
        <link>https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</link>
        <pubDate>Tue, 17 Jun 2025 18:27:49 +0800</pubDate>
        
        <guid>https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</guid>
        <description>&lt;p&gt;开个坑，主要是记录后续复习操作系统的一些笔记与完成 6.S081 课程的 lab 。&lt;/p&gt;
&lt;h2 id=&#34;1-概述&#34;&gt;1. 概述
&lt;/h2&gt;&lt;p&gt;操作系统的定义：操作系统是一组&lt;strong&gt;控制和管理&lt;/strong&gt;计算机软硬件资源，合理地&lt;strong&gt;组织&lt;/strong&gt;多道程序的运行，方便用户使用的程序的集合。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作系统是系统资源的管理者（处理机管理，存储器管理，文件管理，设备管理）；&lt;/li&gt;
&lt;li&gt;操作系统要向上提供方便易用的服务（GUI 接口，联机命令接口 = 交互式命令接口， 脱机命令接口 = 批处理命令接口，程序接口）；&lt;/li&gt;
&lt;li&gt;操作系统是最接近硬件的一层软件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;简述操作系统的基本特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;并发：指两个或多个事件在同一时间间隔内发生。宏观上同时发生，微观上交替发生。（并发 vs 并行）&lt;/li&gt;
&lt;li&gt;共享：系统中的资源可被多个并发执行的进程共同使用。并发性与共享性互为存在条件。&lt;/li&gt;
&lt;li&gt;虚拟：将物理实体映射成若干个逻辑设备。没有并发性，实现虚拟性就没有意义。（虚拟处理器技术：时分复用技术；虚拟存储器技术：空分复用技术）&lt;/li&gt;
&lt;li&gt;异步：多道程序下，由于资源有限，进程的执行是走走停停，以不可预知的速度向前推进。只有系统拥有并发性，才有可能导致异步性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;操作系统的运行机制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;内核程序 vs 应用程序
CPU 执行的程序分为两种：操作系统内核程序、用户程序；
内核是操作系统最基础、核心的那部分；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特权指令 vs 非特权指令
内核程序，在计算机中的地位充当管理程序 ，所以可以执行特权指令；
用户程序，在计算机中的地位充当被管理程序 ，出于安全考虑只能执行非特权指令；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;内核态 vs 用户态
【问题】CPU 可以区分特权指令和非特权指令 ，但是 CPU 无法识别正在执行的指令是应用程序的指令，还是内核程序的指令。
答：为了让 CPU 能够区分应用程序和内核程序 ，CPU会被划分为两种状态：内核态和用户态。&lt;/p&gt;
&lt;p&gt;内核态 - 内核程序 - 可以执行特权指令；
用户态 - 应用程序 - 只能执行非特权指令；&lt;/p&gt;
&lt;p&gt;CPU使用程序状态字寄存器（PSW） 实现对CPU状态的标记。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何变态 ？
内核态转向用户态：执行一条特权指令，修改 PSW 的标志位为用户态；
用户态转向内核态：由&lt;strong&gt;中断&lt;/strong&gt;引发，硬件自动完成变态过程；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;中断与异常：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中断的作用：让操作系统内核强行夺回 CPU 控制权；使 CPU 从用户态变为内核态。（没有中断就无法实现并发）&lt;/li&gt;
&lt;li&gt;分类：
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1.png&#34;
	width=&#34;1081&#34;
	height=&#34;578&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1_hu_ead3e0e924f55276.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/1_hu_b4fea16bbcb9f663.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;中断与异常&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;187&#34;
		data-flex-basis=&#34;448px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;中断机制的基本原理：不同的中断信号，需要查询“中断信号表”来找到不同的中断处理程序来处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;系统调用：是操作系统提供给用户程序使用的接口，可以理解为一种特殊函数，应用程序可以通过系统调用来请求获得操作系统内核的服务。凡是与共享资源有关的操作，都必须通过系统调用的方式向操作系统内核提出服务请求。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;过程：
&lt;ul&gt;
&lt;li&gt;一个应用程序运行在用户态，那么它的指令会CPU被一条条执行；&lt;/li&gt;
&lt;li&gt;当他想发出系统调用的时候，他需要&lt;strong&gt;传参指令&lt;/strong&gt;给CPU的寄存器传入某个参数，这个参数指明要进行哪种系统调用；传参指令可能多条，主要看需要的系统调用要求几个参数；&lt;/li&gt;
&lt;li&gt;当参数都传入寄存器之后，用户程序就会执行&lt;strong&gt;陷入指令&lt;/strong&gt;，这个陷入指令得到执行会引发一个内中断；&lt;/li&gt;
&lt;li&gt;CPU 检测到内部中断，发现这个内中断是由 &lt;strong&gt;trap 指令&lt;/strong&gt;引起的，就会暂停处理应用程序，转入相应的中断处理程序；&lt;/li&gt;
&lt;li&gt;CPU 转为内核态，&lt;strong&gt;处理系统调用入口程序&lt;/strong&gt;，根据参数判断需要哪种系统调用；对应系统调用的处理程序根据传入的其它参数，看看用户程序需要哪些具体服务；&lt;/li&gt;
&lt;li&gt;系统调用处理完，CPU切换为用户态，继续之前的用户程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;操作系统的体系结构：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作系统的内核
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2.png&#34;
	width=&#34;1063&#34;
	height=&#34;534&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2_hu_46d683e60773cba9.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/2_hu_867744d52652fd16.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;操作系统的内核&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;199&#34;
		data-flex-basis=&#34;477px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;大内核与微内核
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3.png&#34;
	width=&#34;822&#34;
	height=&#34;332&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3_hu_9db5b6c9b3d2f826.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/3_hu_9a944c78eade466.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;大内核与微内核&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;247&#34;
		data-flex-basis=&#34;594px&#34;
	
&gt;&lt;/li&gt;
&lt;li&gt;分层结构：每一层只能调用更低、相邻的那一层提供的功能接口；&lt;/li&gt;
&lt;li&gt;模块化：将操作系统分成多个模块，各模块之间协调工作；&lt;/li&gt;
&lt;li&gt;外核：用户直接使用硬件资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开机过程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;操作系统要启动运行，操作系统的数据就需要被放进主存里面；计算机的主存，由 RAM 和 ROM 组成；ROM 存储芯片里存储 BIOS（基本输入输出系统），BIOS 里包含 ROM 引导程序。&lt;/li&gt;
&lt;li&gt;CPU 从一个特定主存地址开始，取指令，执行 ROM 中的引导程序（先进行硬件自检，再开机）；&lt;/li&gt;
&lt;li&gt;ROM 引导程序指示 CPU 将磁盘的第一块&amp;ndash;主引导记录读入内存，执行磁盘引导程序，扫描分区表；&lt;/li&gt;
&lt;li&gt;磁盘引导程序会根据分区表去找到C盘的位置，之后 CPU 读入 C 盘的引导记录 PBR。PBR 本身也是一种程序，CPU 就执行 PBR 里的程序，PBR 程序的主要作用就是找到启动管理器。启动管理器是在根目录里的一个程序，找到启动管理器，CPU 运行它，就开始了操作系统初始化的一系列操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-进程与线程&#34;&gt;2. 进程与线程
&lt;/h2&gt;&lt;h3 id=&#34;21-进程与线程&#34;&gt;2.1 进程与线程
&lt;/h3&gt;&lt;p&gt;进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位；&lt;/p&gt;
&lt;p&gt;​进程实体包括：PCB + 程序段 + 数据段 三部分；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PCB：进程描述信息（PID，UID）、进程控制和管理信息、资源分配信息；&lt;/li&gt;
&lt;li&gt;程序段：程序的代码；&lt;/li&gt;
&lt;li&gt;数据段：运行过程中出生的各种数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进程的特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡的；&lt;/li&gt;
&lt;li&gt;并发性：内存中有多个进程实体，各进程可并发执行；&lt;/li&gt;
&lt;li&gt;独立性：进程是能独立运行、独立获得资源、独立接受调度的基本单位；&lt;/li&gt;
&lt;li&gt;异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供“进程同步机制&amp;quot;来解决异步问题；&lt;/li&gt;
&lt;li&gt;结构性：每个进程都会配置一个PCB。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进程的状态与转换：
&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4.png&#34;
	width=&#34;1340&#34;
	height=&#34;751&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4_hu_6c47587e6f604052.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/4_hu_d0d533a934efe671.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;进程的状态与转换&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;178&#34;
		data-flex-basis=&#34;428px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;进程的组织方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;链接方式：将同一状态的 PCB 链接成一个链表；&lt;/li&gt;
&lt;li&gt;索引方式：将同一状态的进程组织在一个索引表中，索引表的表项指向相应的 PCB。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进程的控制：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;进程的创建&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;申请空白 PCB；&lt;/li&gt;
&lt;li&gt;为新进程分配所需资源；&lt;/li&gt;
&lt;li&gt;初始化 PCB；&lt;/li&gt;
&lt;li&gt;将 PCB 插入就绪队列；&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;进程的终止&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;从 PCB 集中中找到终止进程的 PCB；&lt;/li&gt;
&lt;li&gt;若进程正在运行，立刻剥夺 CPU， 将 CPU 分配给其它进程；&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;进程的阻塞&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;找到要阻塞的进程对应的 PCB；&lt;/li&gt;
&lt;li&gt;保护进程运行现场，将 PCB 状态信息设置为 阻塞态，暂时停止进程执行；&lt;/li&gt;
&lt;li&gt;将 PCB 插入相应事件的等待队列；&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;进程的唤醒&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;在事件等待队列中找到PCB；&lt;/li&gt;
&lt;li&gt;将 PCB 从等待队列移除，设置进程为就绪态；&lt;/li&gt;
&lt;li&gt;将 PCB 插入就绪队列，等待被调度；&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;进程状态的切换&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;将运行环境信息存入 PCB；&lt;/li&gt;
&lt;li&gt;PCB 移入相应队列；&lt;/li&gt;
&lt;li&gt;选择另一个进程执行，并更新其 PCB；&lt;/li&gt;
&lt;li&gt;根据 PCB 回复新进程所需的运行环境；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进程的通信&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;共享存储：相互通信的进程互斥地共享某些数据结构或存储区，进程之间能够通过这些空间进行通信；&lt;/li&gt;
&lt;li&gt;消息传递：进程之间的数据交换以格式化的信息为单位，将通信的数据封装在信息中，并利用操作系统提供的一组通信命令（原语），在进程间进行信息传递，完成进程间的数据交换；
&lt;ul&gt;
&lt;li&gt;直接通信方式：送货上门&lt;/li&gt;
&lt;li&gt;间接通信方式：快递到驿站&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;管道通信&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;线程：减少程序在并发执行时所付出的时间开销，提高 OS 的并发性能；引入线程后，进程是资源分配的基本单位，线程是调度的基本单位。线程的实现方式包括用户级线程与内核级线程。TCB 线程控制块；TID 线程标识符。&lt;/p&gt;
&lt;h3 id=&#34;22-处理机调度&#34;&gt;2.2 处理机调度
&lt;/h3&gt;&lt;p&gt;处理机调度：进程数 &amp;gt; 处理机个数，需要对处理机进行分配。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5.png&#34;
	width=&#34;1271&#34;
	height=&#34;579&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5_hu_b737851000d516bc.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/5_hu_827e6aa394d3703f.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;三层调度&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;219&#34;
		data-flex-basis=&#34;526px&#34;
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>学习笔记-机器学习</title>
        <link>https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
        <pubDate>Mon, 16 Jun 2025 19:29:56 +0800</pubDate>
        
        <guid>https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid>
        <description>&lt;h2 id=&#34;0-算法速览&#34;&gt;0 算法速览
&lt;/h2&gt;&lt;p&gt;监督学习算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;线性回归（Linear Regression）：用于回归任务，预测连续的数值。&lt;/li&gt;
&lt;li&gt;逻辑回归（Logistic Regression）：用于二分类任务，预测类别。&lt;/li&gt;
&lt;li&gt;决策树（Decision Tree）：基于树状结构进行决策的分类或回归方法。&lt;/li&gt;
&lt;li&gt;支持向量机（SVM）：用于分类任务，构建超平面进行分类。&lt;/li&gt;
&lt;li&gt;K近邻算法&lt;/li&gt;
&lt;li&gt;集成学习&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无监督学习算法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;K-means 聚类：通过聚类中心将数据分组。&lt;/li&gt;
&lt;li&gt;主成分分析（PCA）：用于降维，提取数据的主成分。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;01-线性回归&#34;&gt;0.1 线性回归
&lt;/h3&gt;&lt;p&gt;线性回归 (Linear Regression) 是一种用于预测连续值的最基本的机器学习算法，它假设目标变量 y 和特征变量 x 之间存在线性关系，并试图找到一条最佳拟合直线来描述这种关系。&lt;/p&gt;
&lt;p&gt;常用的误差函数是均方误差 (MSE) : $MSE = 1/n * Σ(y_i - y_{pred_i})^2$&lt;/p&gt;
&lt;h4 id=&#34;求解方法-最小二乘法&#34;&gt;求解方法-最小二乘法
&lt;/h4&gt;&lt;p&gt;最小二乘法的目标是最小化残差平方和（RSS），其公式为：$RSS = \sum_{i=1}^n(y_i - \hat{y}_i)^2$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1.jpg&#34;
	width=&#34;1440&#34;
	height=&#34;1080&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1_hu_dc3fae64383c103d.jpg 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/1_hu_cb0bc3cbb612de23.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;推导&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;133&#34;
		data-flex-basis=&#34;320px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;得到最佳的 $w, b$&lt;/p&gt;
$$
\begin{bmatrix} w \\ b \end{bmatrix} = \begin{bmatrix} \sum_{i=1}^n x_i^2 &amp; \sum_{i=1}^n x_i \\ \sum_{i=1}^n x_i &amp; n \end{bmatrix}^{-1} \begin{bmatrix} \sum_{i=1}^n x_i y_i \\ \sum_{i=1}^n y_i \end{bmatrix}
$$&lt;h4 id=&#34;求解方法-梯度下降法&#34;&gt;求解方法-梯度下降法
&lt;/h4&gt;&lt;p&gt;梯度下降法的目标是最小化损失函数 $J(w,b)$ 。对于线性回归问题，通常使用均方误差（MSE）作为损失函数：&lt;/p&gt;
$$ J(w, b) = \frac{1}{2m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 $$&lt;p&gt;参数更新：&lt;/p&gt;
$$ w := w - \alpha \frac{\partial J}{\partial w} \quad b := b - \alpha \frac{\partial J}{\partial b} $$&lt;p&gt;梯度下降法的步骤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化参数：初始化 w 和 b 的值（通常设为 0 或随机值）。&lt;/li&gt;
&lt;li&gt;计算损失函数：计算当前参数下的损失函数值 $J(w,b)$ 。&lt;/li&gt;
&lt;li&gt;计算梯度：计算损失函数对 w 和 b 的偏导数。&lt;/li&gt;
&lt;li&gt;更新参数：根据梯度更新 w 和 b。&lt;/li&gt;
&lt;li&gt;重复迭代：重复步骤 2 到 4，直到损失函数收敛或达到最大迭代次数。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;02-逻辑回归&#34;&gt;0.2 逻辑回归
&lt;/h3&gt;&lt;p&gt;逻辑回归（Logistic Regression）是一种广泛应用于分类问题的统计学习方法，尽管名字中带有&amp;quot;回归&amp;quot;，但它实际上是一种用于二分类或多分类问题的算法。&lt;/p&gt;
&lt;p&gt;逻辑回归通过使用逻辑函数（也称为 Sigmoid 函数）将线性回归的输出映射到 0 和 1 之间，从而预测某个事件发生的概率。建立模型：&lt;/p&gt;
\[
p(y = 1|X) = \sigma(w^T X + b)
\]&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( X \) 是输入特征（可以是多个特征组成的向量）。&lt;/li&gt;
&lt;li&gt;\( w \) 是权重向量。&lt;/li&gt;
&lt;li&gt;\( b \) 是偏置项。&lt;/li&gt;
&lt;li&gt;\(\sigma(z) = \frac{1}{1+e^{-z}}\) 是Sigmoid函数。Sigmoid函数将模型的输出值 \((w^T X + b)\) 映射到0到1之间，因此它可以看作是属于类别1的概率。注意 $\sigma&amp;rsquo;(z) = \sigma(z)(1 - \sigma(z))$ 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用对数损失函数&lt;/p&gt;
\[ L(\theta) = 
  \begin{cases} 
   -\log(p), &amp; \text{if } y = 1 \\
   -\log(1-p), &amp; \text{if } y = 0 
  \end{cases}
\]&lt;p&gt;合并得到单个样品的损失函数&lt;/p&gt;
\[ 
    L(\theta) = -ylog(p)-(1-y)log(1-p)
\]&lt;p&gt;因此总体损失函数（也就是交叉熵损失函数）&lt;/p&gt;
\[ L(\theta) = -\frac{1}{m} \sum_{i=1}^{m} \left[ y^{(i)} \log(p^{(i)}) + (1 - y^{(i)}) \log(1 - p^{(i)}) \right] \]&lt;h4 id=&#34;求解方法-梯度下降法-1&#34;&gt;求解方法-梯度下降法
&lt;/h4&gt;&lt;p&gt;对 \(w\) 的梯度：
&lt;/p&gt;
\[ \frac{\partial J(w, b)}{\partial w} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x^{(i)} \]&lt;p&gt;对 \(b\) 的梯度：
&lt;/p&gt;
\[ \frac{\partial J(w, b)}{\partial b} = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \]&lt;p&gt;&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2.jpg&#34;
	width=&#34;1279&#34;
	height=&#34;1706&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2_hu_e9d3f2f7cdc08657.jpg 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2_hu_1c4e3fb87193097c.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;推导&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;74&#34;
		data-flex-basis=&#34;179px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;03-决策树&#34;&gt;0.3 决策树
&lt;/h3&gt;&lt;p&gt;决策树（Decision Tree），它是一种以树形数据结构来展示决策规则和分类结果的模型，作为一种归纳学习算法，其重点是将看似无序、杂乱的已知数据，通过某种技术手段将它们转化成可以预测未知数据的树状模型，每一条从根结点（对最终分类结果贡献最大的属性）到叶子结点（最终分类结果）的路径都代表一条决策的规则。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3.png&#34;
	width=&#34;754&#34;
	height=&#34;561&#34;
	srcset=&#34;https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3_hu_690baba9cb1d5aaf.png 480w, https://mhw-mathcode.github.io/p/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/3_hu_c7dbe716591b324a.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;决策树构建过程&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;134&#34;
		data-flex-basis=&#34;322px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在这个过程中，寻找最优划分属性是决策树过程中的重点，那么应该如何求解呢？&lt;/p&gt;
&lt;h4 id=&#34;求解方法-信息增益&#34;&gt;求解方法-信息增益
&lt;/h4&gt;&lt;p&gt;首先引入信息熵的概念&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;信息熵：描述随机变量的不确定性（也就是混乱程度）。
假设某随机变量的概率分布为：$P(X=x_i) = p_i, \quad i = 1, 2, \ldots, n$ ，则它的信息熵计算公式为：$H(X) = - \sum_{i=1}^{n} p_i \log p_i$&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;在决策树中，信息熵&lt;/p&gt;
\[ H(D) = - \sum_{k=1}^{K} \frac{|D_k|}{|D|} \log \frac{|D_k|}{|D|} \]&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( D \)：整个数据集&lt;/li&gt;
&lt;li&gt;\( D_k \)：第 \( k \) 个类的样本子集&lt;/li&gt;
&lt;li&gt;\( \frac{|D_k|}{|D|} \)：第 \( k \) 类的概率&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;条件熵&lt;/p&gt;
\[ H(D|A) = \sum_{i=1}^{n} \frac{|D_i|}{|D|} H(D_i) \]&lt;p&gt;\( H(D_i) \) 是每个子集 \( D_i \) 的信息熵&lt;/p&gt;
\[ H(D_i) = - \sum_{k=1}^{K} \frac{|D_{ik}|}{|D_i|} \log \frac{|D_{ik}|}{|D_i|} \]&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( A \)：某个属性&lt;/li&gt;
&lt;li&gt;\( D_i \)：属性 \( A \) 的第 \( i \) 个取值所对应的数据子集&lt;/li&gt;
&lt;li&gt;\( D_{ik} \)：在第 \( i \) 个子集中属于第 \( k \) 类的样本数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因此有&lt;/p&gt;
\[ H(D|A) = - \sum_{i=1}^{n} \frac{|D_i|}{|D|} \sum_{k=1}^{K} \frac{|D_{ik}|}{|D_i|} \log \frac{|D_{ik}|}{|D_i|} \]&lt;p&gt;特征 \( A \) 对训练数据集 \( D \) 的信息增益 \( gain(D, A) \) 定义为集合 \( D \) 的信息熵 \( H(D) \) 与特征 \( A \) 给定条件下 \( D \) 的信息条件熵 \( H(D|A) \) 之差，即公式为：&lt;/p&gt;
\[ gain(D, A) = H(D) - H(D|A) \]&lt;p&gt;信息增益表示得知特征 \( X \) 的信息而使得类 \( Y \) 的信息的不确定性减少的程度，因此信息增益最大的属性就是最优划分属性，标志性算法 $ID3$ 。&lt;/p&gt;
&lt;h4 id=&#34;求解方法-增益比&#34;&gt;求解方法-增益比
&lt;/h4&gt;&lt;p&gt;信息增益虽然在理论上可以找到最优的划分属性，但在某些情况下会存在问题。信息增益比较偏好可取值较多的属性。因此为了矫正信息增益偏好的问题，使算法不偏向可取值较多的属性，引申出了增益比的思想。&lt;/p&gt;
\[ Gain\_ratio(D, A) = \frac{Gain(D, A)}{H(A)} \]&lt;p&gt;可以看出，增益比就是信息增益除以属性 $A$ 的信息熵，当属性 $A$ 可取值增多的时候，$H(A)$ 一般也增大，因此在一定程度上能抑制信息增益偏好取值多的属性的特点，但是增益比偏好取值较少的属性。&lt;/p&gt;
&lt;p&gt;算法 $C4.5$ 是算法 $ID3$ 的改进版，它使用了信息增益和增益比两种选择算法，先选出信息增益高于平均水平的属性，然后再在这些属性中选择增益比最高的，作为最优划分属性。这样综合了信息增益和增益比的优点，可以取得较好的效果。&lt;/p&gt;
&lt;h4 id=&#34;求解方法-基尼指数&#34;&gt;求解方法-基尼指数
&lt;/h4&gt;&lt;p&gt;基尼指数是在样本集中随机抽出两个样本不同类别的概率。当样本集越不纯的时候，这个概率也就越大，即基尼指数也越大。这个规律与信息熵的相同。&lt;/p&gt;
\[ Gini(D) = \sum_{k=1}^{n} \sum_{k&#39; \neq k} p_k p_{k&#39;} = 1 - \sum_{k=1}^{n} p_k^2 \]&lt;p&gt;使用基尼指数来选择最优划分属性也是对比不同属性划分后基尼指数的差值，选择使样本集基尼指数减小最多的属性。&lt;/p&gt;
\[ Gain(D, a) = Gini(D) - \sum_{i=1}^{n} \frac{|D^i|}{|D|} Gini(D^i) \]&lt;p&gt;著名的 $CART$ 决策树就是使用基尼指数来作为划分准则， $CART$ 决策树与 $ID3$ 和 $C4.5$ 的区别：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;划分准则不同，CART决策树使用基尼指数， $ID3$ 和 $C4.5$ 使用信息熵。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$ID3$ 和 $C4.5$ 划分时，一个节点可以划分为多个子结点，子结点数量根据属性可取值的数量决定。而 $CART$ 决策树是严格的二叉树结构，就是说 $1$ 个节点最多划分为 $2$ 子结点。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;04-支持向量机&#34;&gt;0.4 支持向量机
&lt;/h3&gt;&lt;p&gt;支持向量机（Support Vector Machine，简称 SVM）是一种监督学习算法，主要用于分类和回归问题。&lt;/p&gt;
&lt;p&gt;SVM 的核心思想是找到一个最优的超平面，将不同类别的数据分开。这个超平面不仅要能够正确分类数据，还要使得两个类别之间的间隔（margin）最大化。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;支持向量：支持向量是离超平面最近的样本点。这些支持向量对于定义超平面至关重要。支持向量机通过最大化支持向量到超平面的距离（即最大化间隔）来选择最佳的超平面。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;当训练样本&lt;strong&gt;线性可分&lt;/strong&gt;时，通过&lt;strong&gt;硬间隔最大化&lt;/strong&gt;，学习一个&lt;strong&gt;线性可分支持向量机&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;当训练样本&lt;strong&gt;近似线性可分&lt;/strong&gt;时，通过&lt;strong&gt;软间隔最大化&lt;/strong&gt;，学习一个&lt;strong&gt;线性支持向量机&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;当训练样本&lt;strong&gt;线性不可分&lt;/strong&gt;时，通过&lt;strong&gt;核技巧和软间隔最大化&lt;/strong&gt;，学习一个&lt;strong&gt;非线性支持向量机&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;求解方法-间隔最大化和支持向量&#34;&gt;求解方法-间隔最大化和支持向量
&lt;/h4&gt;&lt;p&gt;好难……&lt;/p&gt;
&lt;h3 id=&#34;05-k近邻算法&#34;&gt;0.5 K近邻算法
&lt;/h3&gt;&lt;p&gt;K 近邻算法（K-Nearest Neighbors，简称 KNN）是一种简单且常用的分类和回归算法。&lt;/p&gt;
&lt;p&gt;K 近邻算法属于监督学习的一种，核心思想是通过计算待分类样本与训练集中各个样本的距离，找到距离最近的 K 个样本，然后根据这 K 个样本的类别或值来预测待分类样本的类别或值。&lt;/p&gt;
&lt;h4 id=&#34;求解方法&#34;&gt;求解方法
&lt;/h4&gt;&lt;p&gt;基本步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;计算距离：计算待分类样本与训练集中每个样本的距离。常用的距离度量方法有欧氏距离、曼哈顿距离等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;选择 K 个最近邻：根据计算出的距离，选择距离最近的 K 个样本。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;投票或平均：对于分类问题，K 个最近邻中出现次数最多的类别即为待分类样本的类别；对于回归问题，K 个最近邻的值的平均值即为待分类样本的值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;06-集成学习&#34;&gt;0.6 集成学习
&lt;/h3&gt;&lt;h3 id=&#34;07-k-means-聚类&#34;&gt;0.7 K-means 聚类
&lt;/h3&gt;&lt;p&gt;K-means 聚类是一种常用的基于距离的聚类算法，旨在将数据集划分为 K 个簇。算法的目标是最小化簇内的点到簇中心的距离总和。&lt;/p&gt;
&lt;h4 id=&#34;求解方法-1&#34;&gt;求解方法
&lt;/h4&gt;&lt;p&gt;基本步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;选择 $K$ 值：设定簇的数量 。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;初始化簇中心：随机选择 $K$ 个数据点作为初始簇中心（centroids）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分配步骤（Assignment Step）：对于数据集中的每个点，将它分配到最近的簇中心对应的簇。这里的“距离”通常使用欧氏距离（Euclidean distance）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新步骤（Update Step）：根据当前的簇分配，重新计算每个簇的中心，即计算簇内所有点的均值作为新的簇中心。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重复 3 和 4 步：不断重复分配和更新步骤，直到簇中心不再发生变化（收敛）或达到指定的最大迭代次数。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;确定最佳的簇数 $K$ 是 $K-means$ 聚类中的一个难点。聚类的目标是使得每个样本点到距离其最近的聚类中心的总误差平方和（也即聚类的代价函数，记作 $SSE$ ）尽可能小。&lt;/p&gt;
&lt;p&gt;空间中数据对象与聚类中心间的欧式距离计算公式为：&lt;/p&gt;
\[ d(x, C_i) = \sqrt{\sum_{j=1}^{m} (x_j - C_{ij})^2} \]&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;\( x \) 为数据对象，&lt;/li&gt;
&lt;li&gt;\( C_i \) 为第 \( i \) 个聚类中心，&lt;/li&gt;
&lt;li&gt;\( m \) 为数据对象的维度，&lt;/li&gt;
&lt;li&gt;\( x_j \)，\( C_{ij} \) 为 \( x \) 和 \( C_i \) 的第 \( j \) 个属性值。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;整个数据集的误差平方和 SSE 计算公式为：&lt;/p&gt;
\[ SSE = \sum_{i=1}^{k} \sum_{x \in C_i} |d(x, C_i)|^2 \]&lt;p&gt;其中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SSE 的大小表示聚类结果的好坏，&lt;/li&gt;
&lt;li&gt;\( k \) 为簇的个数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;理论上随着 $K$ 的增加， $SSE$ 会单调递减，当 $K$ 超过某一个数后，每个类簇的聚合程度不再获得显著提升，此时我们就可以认为已找到最佳 $K$ 的取值（肘部法）。&lt;/p&gt;
&lt;h4 id=&#34;k-means&#34;&gt;K-means++
&lt;/h4&gt;&lt;p&gt;K-means++ 是一种改进的初始化方法，可以帮助选择更合理的初始中心，优先选择“距离最远”的点作为初始质心，减少陷入局部最优的风险。&lt;/p&gt;
&lt;p&gt;基本步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;从数据集 $\mathcal{X}$ 中随机（均匀分布）选取一个样本点作为第一个初始聚类中心;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;接着计算每个样本与当前已有聚类中心之间的最短距离，用 $D(x)$ 表示；然后计算每个样本点被选为下一个聚类中心的概率 $P(x) = \frac{D(x)^2}{\sum_{x \in \mathcal{X}} D(x)^2}$，最后选择最大概率值（或者概率分布）所对应的样本点作为下一个簇中心；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重复步骤 2，直到选择 $K$ 个聚类中心&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;优势：避免随机初始化，加快收敛速度，聚类结果更加稳定。&lt;/p&gt;
&lt;h3 id=&#34;08-主成分分析&#34;&gt;0.8 主成分分析
&lt;/h3&gt;&lt;p&gt;主成分分析（PCA）是一种无监督学习方法，旨在通过线性变换将原始的高维数据映射到一个低维空间，同时尽可能保留数据的方差（即信息量）。简单来说，PCA 的目标是找到一组新的坐标轴（称为主成分），这些坐标轴能够捕捉数据中最大的变异性，并用更少的维度来近似表示原始数据。&lt;/p&gt;
&lt;h4 id=&#34;求解方法-2&#34;&gt;求解方法
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;数据中心化：首先将数据中心化，即让每个特征的均值变为 0。&lt;/li&gt;
&lt;li&gt;计算协方差矩阵：&lt;/li&gt;
&lt;/ol&gt;
\[ \text{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y}) \]&lt;p&gt;协方差为正时，说明X和Y是正相关关系；协方差为负时，说明X和Y是负相关关系；协方差为0时，说明X和Y是相互独立。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;特征值分解：对协方差矩阵进行特征值分解，得到主成分的方向（特征向量）和重要性（特征值）。令\( A \) 是协方差矩阵，\( \lambda \) 是特征值，\( I \) 是单位矩阵，求解 \[ \det(A - \lambda I) = 0 \]&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;得到特征值 \( \lambda \) 以后代入 $(A - \lambda I)v_1 = 0$ 解得特征向量 $v_1$ 。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;
&lt;p&gt;排序和选择主成分：将特征值从大到小排序，特征值最大的为第一个主成分，捕捉了数据中最大的变化，也就是数据分布中最显著的变化方向。第二个主成分与第一个主成分正交（相互垂直），且在正交约束下方差次大的方向。后续主成分：依此类推，每个主成分都与前面的主成分正交，并按特征值大小递减排列。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;投影数据：将中心化后的数据投影到第一个主成分上，得到降维后的结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;一些问题&#34;&gt;一些问题
&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;为什么要计算协方差矩阵？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;PCA 的目标是找到一组新的坐标轴（称为主成分），使得数据在这些轴上的投影方差最大化，同时这些轴相互正交（不相关）。协方差矩阵正好量化了数据中的变异性和变量间的相关性，我们可以了解到哪些变量变化较大，哪些变量之间存在较强的关联，为找到这样的轴提供了基础。&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;为什么要进行特征值分解？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;特征值表示每个特征向量方向上的方差大小。特征值越大，说明该方向捕捉的变异性越多。通过特征值分解，我们可以将原始数据投影到这些特征向量上，从而实现降维，同时尽可能保留数据的信息。&lt;/p&gt;
&lt;h2 id=&#34;1-引言&#34;&gt;1 引言
&lt;/h2&gt;&lt;h3 id=&#34;11-什么是机器学习&#34;&gt;1.1 什么是机器学习
&lt;/h3&gt;&lt;p&gt;一个好的学习问题定义如下：一个程序被认为能从经验 E 中学习，解决任务 T ，达到性能度量值 P ，当且仅当，有了经验 E 后，经过 P 评判，程序在处理 T 时的性能有所提升。&lt;/p&gt;
&lt;p&gt;目前存在几种不同类型的学习算法，其中主要的两种类型被我们称之为：&lt;strong&gt;监督学习&lt;/strong&gt;和&lt;strong&gt;无监督学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;12-监督学习&#34;&gt;1.2 监督学习
&lt;/h3&gt;&lt;p&gt;监督学习：给定带有标签的数据，模型通过学习输入和标签之间的关系来做预测。&lt;/p&gt;
&lt;p&gt;回归 (regression) 问题：推测出这一系列连续值属性。&lt;/p&gt;
&lt;p&gt;分类 (classification) 问题：推测出离散的输出值。&lt;/p&gt;
&lt;h3 id=&#34;13-无监督学习&#34;&gt;1.3 无监督学习
&lt;/h3&gt;&lt;p&gt;无监督学习：没有标签的数据，模型通过探索数据中的结构或模式来进行学习。&lt;/p&gt;
&lt;p&gt;聚类算法：将数据集划分成两个不同的簇。&lt;/p&gt;
&lt;p&gt;鸡尾酒算法：分离两种声音。（一个具体实例，仅仅只需要一行代码实现）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-py&#34; data-lang=&#34;py&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;W&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;svd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;repmat&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;2-单变量线性回归-linear-regression-with-one-variable&#34;&gt;2 单变量线性回归 (Linear Regression with One Variable)
&lt;/h2&gt;</description>
        </item>
        
    </channel>
</rss>
